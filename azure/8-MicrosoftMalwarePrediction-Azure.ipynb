{"cells":[{"cell_type":"markdown","source":["# Microsoft Malware Prediction \n\n## MLflow"],"metadata":{}},{"cell_type":"markdown","source":["### Importamos las librer√≠as"],"metadata":{}},{"cell_type":"code","source":["%sh\npip install mlflow"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: mlflow in /databricks/python3/lib/python3.7/site-packages (1.8.0)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.7/site-packages (from mlflow) (0.24.2)\nRequirement already satisfied: querystring-parser in /databricks/python3/lib/python3.7/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: sqlalchemy&lt;=1.3.13 in /databricks/python3/lib/python3.7/site-packages (from mlflow) (1.3.13)\nRequirement already satisfied: protobuf&gt;=3.6.0 in /databricks/python3/lib/python3.7/site-packages (from mlflow) (3.12.1)\nRequirement already satisfied: simplejson in /databricks/python3/lib/python3.7/site-packages (from mlflow) (3.17.0)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.7/site-packages (from mlflow) (2.8.0)\nRequirement already satisfied: gitpython&gt;=2.1.0 in /databricks/python3/lib/python3.7/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: Flask in /databricks/python3/lib/python3.7/site-packages (from mlflow) (1.1.2)\nRequirement already satisfied: docker&gt;=4.0.0 in /databricks/python3/lib/python3.7/site-packages (from mlflow) (4.2.0)\nRequirement already satisfied: gorilla in /databricks/python3/lib/python3.7/site-packages (from mlflow) (0.3.0)\nRequirement already satisfied: six&gt;=1.10.0 in /databricks/python3/lib/python3.7/site-packages (from mlflow) (1.12.0)\nRequirement already satisfied: prometheus-flask-exporter in /databricks/python3/lib/python3.7/site-packages (from mlflow) (0.13.0)\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.7/site-packages (from mlflow) (5.3.1)\nRequirement already satisfied: click&gt;=7.0 in /databricks/python3/lib/python3.7/site-packages (from mlflow) (7.1.2)\nRequirement already satisfied: databricks-cli&gt;=0.8.7 in /databricks/python3/lib/python3.7/site-packages (from mlflow) (0.10.0)\nRequirement already satisfied: sqlparse in /databricks/python3/lib/python3.7/site-packages (from mlflow) (0.3.1)\nRequirement already satisfied: gunicorn; platform_system != &#34;Windows&#34; in /databricks/python3/lib/python3.7/site-packages (from mlflow) (20.0.4)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.7/site-packages (from mlflow) (1.16.2)\nRequirement already satisfied: alembic in /databricks/python3/lib/python3.7/site-packages (from mlflow) (1.4.2)\nRequirement already satisfied: entrypoints in /databricks/python3/lib/python3.7/site-packages (from mlflow) (0.3)\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.7/site-packages (from mlflow) (1.4.1)\nRequirement already satisfied: requests&gt;=2.17.3 in /databricks/python3/lib/python3.7/site-packages (from mlflow) (2.21.0)\nRequirement already satisfied: pytz&gt;=2011k in /databricks/python3/lib/python3.7/site-packages (from pandas-&gt;mlflow) (2018.9)\nRequirement already satisfied: setuptools in /usr/lib/python3.7/site-packages (from protobuf&gt;=3.6.0-&gt;mlflow) (40.8.0)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /databricks/python3/lib/python3.7/site-packages (from gitpython&gt;=2.1.0-&gt;mlflow) (4.0.5)\nRequirement already satisfied: Jinja2&gt;=2.10.1 in /databricks/python3/lib/python3.7/site-packages (from Flask-&gt;mlflow) (2.11.2)\nRequirement already satisfied: Werkzeug&gt;=0.15 in /databricks/python3/lib/python3.7/site-packages (from Flask-&gt;mlflow) (1.0.1)\nRequirement already satisfied: itsdangerous&gt;=0.24 in /databricks/python3/lib/python3.7/site-packages (from Flask-&gt;mlflow) (1.1.0)\nRequirement already satisfied: websocket-client&gt;=0.32.0 in /databricks/python3/lib/python3.7/site-packages (from docker&gt;=4.0.0-&gt;mlflow) (0.57.0)\nRequirement already satisfied: prometheus-client in /databricks/python3/lib/python3.7/site-packages (from prometheus-flask-exporter-&gt;mlflow) (0.7.1)\nRequirement already satisfied: configparser&gt;=0.3.5 in /databricks/python3/lib/python3.7/site-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow) (5.0.0)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.7/site-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow) (0.8.7)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.7/site-packages (from alembic-&gt;mlflow) (1.1.2)\nRequirement already satisfied: python-editor&gt;=0.3 in /databricks/python3/lib/python3.7/site-packages (from alembic-&gt;mlflow) (1.0.4)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /databricks/python3/lib/python3.7/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.7/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (2019.3.9)\nRequirement already satisfied: urllib3&lt;1.25,&gt;=1.21.1 in /databricks/python3/lib/python3.7/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (1.24.1)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /databricks/python3/lib/python3.7/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (2.8)\nRequirement already satisfied: smmap&lt;4,&gt;=3.0.1 in /databricks/python3/lib/python3.7/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&gt;=2.1.0-&gt;mlflow) (3.0.4)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.7/site-packages (from Jinja2&gt;=2.10.1-&gt;Flask-&gt;mlflow) (1.1.1)\nYou are using pip version 19.0.3, however version 20.2b1 is available.\nYou should consider upgrading via the &#39;pip install --upgrade pip&#39; command.\nERROR: unknown command &#34;unsinstall&#34; - maybe you meant &#34;uninstall&#34;\nCollecting azure-storage-blob==2.1.0\n  Downloading https://files.pythonhosted.org/packages/3e/84/610f379b46d7d3c2d48eadeed6a12b6d46a43100fea70534f5992d0ac996/azure_storage_blob-2.1.0-py2.py3-none-any.whl (88kB)\nCollecting azure-common&gt;=1.1.5 (from azure-storage-blob==2.1.0)\n  Downloading https://files.pythonhosted.org/packages/e5/4d/d000fc3c5af601d00d55750b71da5c231fcb128f42ac95b208ed1091c2c1/azure_common-1.1.25-py2.py3-none-any.whl\nCollecting azure-storage-common~=2.1 (from azure-storage-blob==2.1.0)\n  Downloading https://files.pythonhosted.org/packages/6b/a0/6794b318ce0118d1a4053bdf0149a60807407db9b710354f2b203c2f5975/azure_storage_common-2.1.0-py2.py3-none-any.whl (47kB)\nRequirement already satisfied: cryptography in /databricks/python3/lib/python3.7/site-packages (from azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (2.6.1)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.7/site-packages (from azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (2.21.0)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.7/site-packages (from azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (2.8.0)\nRequirement already satisfied: asn1crypto&gt;=0.21.0 in /databricks/python3/lib/python3.7/site-packages (from cryptography-&gt;azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (0.24.0)\nRequirement already satisfied: cffi!=1.11.3,&gt;=1.8 in /databricks/python3/lib/python3.7/site-packages (from cryptography-&gt;azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (1.12.2)\nRequirement already satisfied: six&gt;=1.4.1 in /databricks/python3/lib/python3.7/site-packages (from cryptography-&gt;azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (1.12.0)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /databricks/python3/lib/python3.7/site-packages (from requests-&gt;azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.7/site-packages (from requests-&gt;azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (2019.3.9)\nRequirement already satisfied: urllib3&lt;1.25,&gt;=1.21.1 in /databricks/python3/lib/python3.7/site-packages (from requests-&gt;azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (1.24.1)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /databricks/python3/lib/python3.7/site-packages (from requests-&gt;azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (2.8)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.7/site-packages (from cffi!=1.11.3,&gt;=1.8-&gt;cryptography-&gt;azure-storage-common~=2.1-&gt;azure-storage-blob==2.1.0) (2.19)\nInstalling collected packages: azure-common, azure-storage-common, azure-storage-blob\n  Found existing installation: azure-storage-blob 12.3.1\n    Uninstalling azure-storage-blob-12.3.1:\n      Successfully uninstalled azure-storage-blob-12.3.1\nSuccessfully installed azure-common-1.1.25 azure-storage-blob-2.1.0 azure-storage-common-2.1.0\nYou are using pip version 19.0.3, however version 20.2b1 is available.\nYou should consider upgrading via the &#39;pip install --upgrade pip&#39; command.\nCollecting snowflake-sqlalchemy\n  Downloading https://files.pythonhosted.org/packages/f9/84/1a9e6e851d57ae29d2f023d07dd554df81c33e5b4742472450aa5f8ea817/snowflake_sqlalchemy-1.2.3-py2.py3-none-any.whl\nRequirement already satisfied: sqlalchemy&lt;2.0.0 in /databricks/python3/lib/python3.7/site-packages (from snowflake-sqlalchemy) (1.3.13)\nCollecting snowflake-connector-python&lt;3.0.0 (from snowflake-sqlalchemy)\n  Downloading https://files.pythonhosted.org/packages/eb/2a/50f38c0d19e966285c434b236ebbcb699521ad52b66045b8e37ff654c092/snowflake_connector_python-2.2.6-cp37-cp37m-manylinux2010_x86_64.whl (12.0MB)\nRequirement already satisfied: boto3&lt;1.14,&gt;=1.4.4 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (1.9.162)\nRequirement already satisfied: azure-common&lt;2.0.0 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (1.1.25)\nRequirement already satisfied: requests&lt;2.24.0 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (2.21.0)\nRequirement already satisfied: cffi&lt;1.14,&gt;=1.9 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (1.12.2)\nRequirement already satisfied: idna&lt;2.10 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (2.8)\nCollecting ijson&lt;3.0.0 (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy)\n  Downloading https://files.pythonhosted.org/packages/19/1d/7c97e1dd574667bbaefc9540feafbcdb8c0641ec2c88410c174b7b95e2cb/ijson-2.6.1-cp37-cp37m-manylinux1_x86_64.whl (65kB)\nCollecting pycryptodomex!=3.5.0,&lt;4.0.0,&gt;=3.2 (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy)\n  Downloading https://files.pythonhosted.org/packages/0f/12/e199901e310840450ce3bf5eaccce21ee75bef65211793c27e98281f1131/pycryptodomex-3.9.7-cp37-cp37m-manylinux1_x86_64.whl (13.7MB)\nCollecting pyjwt&lt;2.0.0 (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy)\n  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\nCollecting asn1crypto&lt;2.0.0,&gt;0.24.0 (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy)\n  Downloading https://files.pythonhosted.org/packages/e9/51/1db4a60049fb7390959be586b6eb743098e6cea3f6b2d3ed9e17fec62ba2/asn1crypto-1.3.0-py2.py3-none-any.whl (103kB)\nRequirement already satisfied: cryptography&lt;3.0.0,&gt;=2.5.0 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (2.6.1)\nCollecting oscrypto&lt;2.0.0 (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy)\n  Downloading https://files.pythonhosted.org/packages/2a/79/4849dadb88f6cddc8ad4c701c11be5cb36434f043c73cebc3b0494943e77/oscrypto-1.2.0-py2.py3-none-any.whl (192kB)\nRequirement already satisfied: azure-storage-blob&lt;12.0.0 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (2.1.0)\nRequirement already satisfied: pytz&lt;2021.0 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (2018.9)\nRequirement already satisfied: urllib3&lt;1.26.0,&gt;=1.20 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (1.24.1)\nRequirement already satisfied: pyOpenSSL&lt;21.0.0,&gt;=16.2.0 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (19.0.0)\nRequirement already satisfied: certifi&lt;2021.0.0 in /databricks/python3/lib/python3.7/site-packages (from snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (2019.3.9)\nRequirement already satisfied: jmespath&lt;1.0.0,&gt;=0.7.1 in /databricks/python3/lib/python3.7/site-packages (from boto3&lt;1.14,&gt;=1.4.4-&gt;snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (0.9.4)\nRequirement already satisfied: botocore&lt;1.13.0,&gt;=1.12.162 in /databricks/python3/lib/python3.7/site-packages (from boto3&lt;1.14,&gt;=1.4.4-&gt;snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (1.12.163)\nRequirement already satisfied: s3transfer&lt;0.3.0,&gt;=0.2.0 in /databricks/python3/lib/python3.7/site-packages (from boto3&lt;1.14,&gt;=1.4.4-&gt;snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (0.2.1)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;2.24.0-&gt;snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (3.0.4)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.7/site-packages (from cffi&lt;1.14,&gt;=1.9-&gt;snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (2.19)\nRequirement already satisfied: six&gt;=1.4.1 in /databricks/python3/lib/python3.7/site-packages (from cryptography&lt;3.0.0,&gt;=2.5.0-&gt;snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (1.12.0)\nRequirement already satisfied: azure-storage-common~=2.1 in /databricks/python3/lib/python3.7/site-packages (from azure-storage-blob&lt;12.0.0-&gt;snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (2.1.0)\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1; python_version &gt;= &#34;2.7&#34; in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.13.0,&gt;=1.12.162-&gt;boto3&lt;1.14,&gt;=1.4.4-&gt;snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (2.8.0)\nRequirement already satisfied: docutils&gt;=0.10 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.13.0,&gt;=1.12.162-&gt;boto3&lt;1.14,&gt;=1.4.4-&gt;snowflake-connector-python&lt;3.0.0-&gt;snowflake-sqlalchemy) (0.14)\nInstalling collected packages: ijson, pycryptodomex, pyjwt, asn1crypto, oscrypto, snowflake-connector-python, snowflake-sqlalchemy\n  Found existing installation: asn1crypto 0.24.0\n    Uninstalling asn1crypto-0.24.0:\n      Successfully uninstalled asn1crypto-0.24.0\nSuccessfully installed asn1crypto-1.3.0 ijson-2.6.1 oscrypto-1.2.0 pycryptodomex-3.9.7 pyjwt-1.7.1 snowflake-connector-python-2.2.6 snowflake-sqlalchemy-1.2.3\nYou are using pip version 19.0.3, however version 20.2b1 is available.\nYou should consider upgrading via the &#39;pip install --upgrade pip&#39; command.\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["import mlflow\nimport mlflow.sklearn\nimport pandas as pd\nimport numpy as np\nimport pickle\nimport azureml\nimport mlflow.azureml\n\nfrom azureml.core import Workspace\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nfrom sklearn import metrics\nfrom azure.storage.blob import BlockBlobService\nfrom azureml.core.webservice import AciWebservice, Webservice"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["### Descargar los datos"],"metadata":{}},{"cell_type":"code","source":["# Descargamos todos los ficheros del contenedor de datos\n\n# 1. Nos autenticamos\nSTORAGEACCOUNTNAME = \"datostfm\"\nSTORAGEACCOUNTKEY = \"BAypoQhwJHFW/dwMM72rikWyxFlhFKmAlds6nQ7FXvuu0f1G1qBKWVW5wwrqI0lrq38hb35BAILSCtg/sgLObQ==\"\nCONTAINERNAME = \"datos\"\nblob_service = BlockBlobService(account_name=STORAGEACCOUNTNAME, account_key=STORAGEACCOUNTKEY)\n\n# 2. Descargamos del Blob\nLOCALFILENAME = [\"X_train.csv\", \"X_val.csv\", \"y_train.csv\", \"y_val.csv\"]\nBLOBNAME = LOCALFILENAME\nfor csv in LOCALFILENAME:\n    blob_service.get_blob_to_path(CONTAINERNAME, csv, csv)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Convertimos a pandas\nX_train = pd.read_csv(LOCALFILENAME[0])\nX_val = pd.read_csv(LOCALFILENAME[1])\ny_train = pd.read_csv(LOCALFILENAME[2])\ny_val = pd.read_csv(LOCALFILENAME[3])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["### Descargar los modelos"],"metadata":{}},{"cell_type":"code","source":["# Descargamos los modelos del contenedor\n\n# 1. Nos autenticamos\nSTORAGEACCOUNTNAME = \"datostfm\"\nSTORAGEACCOUNTKEY = \"BAypoQhwJHFW/dwMM72rikWyxFlhFKmAlds6nQ7FXvuu0f1G1qBKWVW5wwrqI0lrq38hb35BAILSCtg/sgLObQ==\"\nCONTAINERNAME = \"modelos\"\nblob_service = BlockBlobService(account_name=STORAGEACCOUNTNAME, account_key=STORAGEACCOUNTKEY)\n\n# 2. Descargamos del Blob\nLOCALFILENAME = [\"random_forest.pkl\", \"regresion_logistica.pkl\", \"gradient_boosting.pkl\"]\nBLOBNAME = LOCALFILENAME\nfor csv in LOCALFILENAME:\n    blob_service.get_blob_to_path(CONTAINERNAME, csv, csv)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Cargamos el modelo para Random Forest\npkl_filenameRF = \"random_forest.pkl\"\nwith open(pkl_filenameRF, 'rb') as file:\n    rf_model = pickle.load(file)\n\n# Cargamos el modelo para Regresi√≥n Log√≠stica\npkl_filenameRL = \"regresion_logistica.pkl\"\nwith open(pkl_filenameRL, 'rb') as file:\n    rl_model = pickle.load(file)\n    \n# Cargamos el modelo para Gradient Boosting\npkl_filenameGB = \"gradient_boosting.pkl\"\nwith open(pkl_filenameGB, 'rb') as file:\n    gb_model = pickle.load(file)    "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["### Poner en producci√≥n los modelos"],"metadata":{}},{"cell_type":"markdown","source":["**Definir las m√©tricas**"],"metadata":{}},{"cell_type":"code","source":["def eval_metricas(y_val, y_pred):\n    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n    mae = mean_absolute_error(y_val, y_pred)\n    logloss = metrics.log_loss(y_val, y_pred)\n    accuracy = metrics.accuracy_score(y_val, y_pred)\n    F1 = metrics.f1_score(y_val, y_pred)\n    precision = precision_score(y_val, y_pred, average='binary')\n    recall = recall_score(y_val, y_pred, average='binary')\n    auc = metrics.roc_auc_score(y_val, y_pred)\n    \n    return (rmse, mae, logloss, accuracy, F1, precision, recall, auc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["#### Algoritmo de Random Forest"],"metadata":{}},{"cell_type":"markdown","source":["Necesitamos primero **crear la instancia del modelo en MLflow**. Podemos ver cada una de las ejecuciones dentro de la GUI de Databricks, gracias a la integraci√≥n de MLflow. Al hacer clic en cada entrada, se devuelven los detalles de la ejecuci√≥n, los archivos que definen el modelo y mucho m√°s. Y al hacer clic en la pesta√±a _Runs_ en la esquina superior derecha, observamos que podemos ver detalles sobre cada una de nuestras ejecuciones realizadas con MLflow."],"metadata":{}},{"cell_type":"code","source":["# Iniciamos 'mlflow'\nwith mlflow.start_run():\n    \n    # Obtenemos las predicciones con el modelo 01  \n    predict = rf_model.predict(X_val)\n    \n    # Calculamos diversas medidas\n    (rmse, mae, logloss, accuracy, F1, precision, recall, auc) = eval_metricas(y_val, predict)\n\n    # Log mlflow par√°metros\n    mlflow.log_metric(\"rmse\", rmse)\n    mlflow.log_metric(\"mae\", mae)\n    mlflow.log_metric(\"logloss\", logloss)\n    mlflow.log_metric(\"accuracy\", accuracy)\n    mlflow.log_metric(\"F1\", F1)\n    mlflow.log_metric(\"precision\", precision)\n    mlflow.log_metric(\"recall\", recall)\n    mlflow.log_metric(\"auc\", auc)\n\n    # Log modelo generado\n    mlflow.sklearn.log_model(rf_model, \"RFmodel\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["Ahora **cargamos nuestro modelo MLflow** (que se guard√≥ en nuestro pipeline MLflow anteriormente) y lo cargamos en una variable para la puntuaci√≥n por lotes (batch). Para encontrar la ruta del modelo que queremos desplegar, debemos ir a la informaci√≥n de la ejecuci√≥n del modelo en MLflow.\n\n`dbfs:/databricks/mlflow/443106500331548/654e005f60fd4040bbd62a0e9fc0e50f/artifacts/RFmodel`"],"metadata":{}},{"cell_type":"code","source":["model_path = \"dbfs:/databricks/mlflow/443106500331548/654e005f60fd4040bbd62a0e9fc0e50f/artifacts/RFmodel\"\ndbutils.fs.ls(model_path)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: [FileInfo(path=&#39;dbfs:/databricks/mlflow/443106500331548/654e005f60fd4040bbd62a0e9fc0e50f/artifacts/RFmodel/MLmodel&#39;, name=&#39;MLmodel&#39;, size=345),\n FileInfo(path=&#39;dbfs:/databricks/mlflow/443106500331548/654e005f60fd4040bbd62a0e9fc0e50f/artifacts/RFmodel/conda.yaml&#39;, name=&#39;conda.yaml&#39;, size=136),\n FileInfo(path=&#39;dbfs:/databricks/mlflow/443106500331548/654e005f60fd4040bbd62a0e9fc0e50f/artifacts/RFmodel/model.pkl&#39;, name=&#39;model.pkl&#39;, size=131472984)]</div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["Antes de que los modelos se puedan implementar en Azure ML, se debe **crear un Azure ML Workspace**. La funci√≥n `azureml.core.Workspace.create()` cargar√° un espacio de trabajo con un nombre especificado o crear√° uno si a√∫n no existe (hacemos uso de un recurso ya creado, y buscamos los valores de la configuraci√≥n que necesitamos). Cuando ejecutamos esa funci√≥n, es necesario autenticarse, a trav√©s de la URL, y meter un c√≥digo de autenticaci√≥n."],"metadata":{}},{"cell_type":"code","source":["workspace_name = \"ML-TFM\"\nworkspace_location = \"southcentralus\"\nresource_group = \"TFM_GroupResource\"\nsubscription_id = \"678e98bc-31b5-4562-9651-04fef641d4b3\"\n\nworkspace = Workspace.create(name = workspace_name, subscription_id = subscription_id, resource_group = resource_group, \n                             location = workspace_location, exist_ok=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Performing interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FKDGDLN7T to authenticate.\nInteractive authentication successfully completed.\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["**Construimos nuestro modelo de Random Forest** previamente entrenado y almacenado en MLflow en una imagen desplegable de Docker usando solo 3 l√≠neas de c√≥digo. Para crear el contenedor, se hace uso de YAML a trav√©s del fichero que se nos crea con el modelo en MLflow. Con la ejecuci√≥n, vemos que nuestro modelo se registra en Azure ML Workspace."],"metadata":{}},{"cell_type":"code","source":["model_image, azure_model = mlflow.azureml.build_image(model_uri=model_path, \n                                                      workspace=workspace, \n                                                      model_name=\"model-rf-malware\",\n                                                      image_name=\"model-rf-malware-container-image\",\n                                                      description=\"mlflow rf model for scoring machine malware infection status\",\n                                                      synchronous=False)\nmodel_image.wait_for_creation(show_output=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registering model model-rf-malware\n/databricks/python/lib/python3.7/site-packages/mlflow/azureml/__init__.py:202: DeprecationWarning: ContainerImage class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n  tags=tags,\n/databricks/python/lib/python3.7/site-packages/azureml/core/image/container.py:159: DeprecationWarning: ContainerImageConfig class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n  base_image, base_image_registry, cuda_version=cuda_version)\n/databricks/python/lib/python3.7/site-packages/mlflow/azureml/__init__.py:207: DeprecationWarning: Image class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n  models=[registered_model])\nCreating image\n/databricks/python/lib/python3.7/site-packages/azureml/core/image/image.py:401: DeprecationWarning: Image class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n  image = Image(workspace, id=image_id)\nRunning...................................................................\nSucceeded\nImage creation operation finished for image model-rf-malware-container-image:2, operation &#34;Succeeded&#34;\n</div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["Una vez tenemos nuestro modelo, tenemos que pasar a **crear la implementaci√≥n del modelo**. Para ello hay que crear un ACI (Azure Container Instances) y hacer el despliegue de servicio web utilizando la imagen del contenedor del modelo."],"metadata":{}},{"cell_type":"code","source":["aci_webservice_name = \"model-rf-malware-aci\"\naci_webservice_deployment_config = AciWebservice.deploy_configuration()\naci_webservice = Webservice.deploy_from_image(name = aci_webservice_name, image = model_image, \n                                              deployment_config = aci_webservice_deployment_config, workspace = workspace)\naci_webservice.wait_for_deployment(show_output=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/local_disk0/tmp/1590233531351-0/PythonShell.py:4: DeprecationWarning: deploy_from_image has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n  import errno\n/databricks/python/lib/python3.7/site-packages/azureml/core/image/image.py:815: DeprecationWarning: Image class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n  image = cls(None)\nRunning.................................................................................................................................\nSucceeded\nACI service creation operation finished, operation &#34;Succeeded&#34;\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["Para desplegar los otros modelos, simplemente hay que realizar el mismo proceso que acabamos de comentar modificando el modelo que se quiera usar."],"metadata":{}}],"metadata":{"name":"8-MicrosoftMalwarePrediction-Azure","notebookId":443106500331548},"nbformat":4,"nbformat_minor":0}
