{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Malware Prediction \n",
    "\n",
    "## MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura del conjunto de datos particionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del conjunto de datos particionado\n",
    "X_train = pd.read_csv(\"./datos/X_train.csv\")\n",
    "X_val = pd.read_csv(\"./datos/X_val.csv\")\n",
    "y_train = pd.read_csv(\"./datos/y_train.csv\")\n",
    "y_val = pd.read_csv(\"./datos/y_val.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definimos las métricas** a evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metricas(y_val, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    logloss = metrics.log_loss(y_val, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    F1 = metrics.f1_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, average='binary')\n",
    "    recall = recall_score(y_val, y_pred, average='binary')\n",
    "    auc = metrics.roc_auc_score(y_val, y_pred)\n",
    "    \n",
    "    return (rmse, mae, logloss, accuracy, F1, precision, recall, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest con MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo 1**\n",
    "\n",
    "~~~python\n",
    "RandomForestClassifier(criterion = 'entropy', max_depth = 12, n_jobs = -1, oob_score = True,\n",
    "                       n_estimators = 100, max_features = \"auto\", min_samples_leaf = 50)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gema/anaconda3/lib/python3.7/site-packages/py4j/java_collections.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import (\n"
     ]
    }
   ],
   "source": [
    "# Iniciamos 'mlflow'\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Cargamos el modelo 01\n",
    "    pkl_filename_01 = \"modelos/random_forest_01.pkl\"\n",
    "    with open(pkl_filename_01, 'rb') as file:\n",
    "        rf_model_01 = pickle.load(file)\n",
    "        \n",
    "    # Obtenemos las predicciones con el modelo 01  \n",
    "    predict_01 = rf_model_01.predict(X_val)\n",
    "    \n",
    "    # Calculamos diversas medidas\n",
    "    (rmse, mae, logloss, accuracy, F1, precision, recall, auc) = eval_metricas(y_val, predict_01)\n",
    "\n",
    "    # Log mlflow parámetros\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"logloss\", logloss)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"F1\", F1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    # Log modelo generado\n",
    "    mlflow.sklearn.log_model(rf_model_01, \"RFmodel01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 01\n",
      " RMSE: 0.603942494738503\n",
      " MAE: 0.3647465369509668\n",
      " Log Loss: 12.598055574220245\n",
      " Accuracy: 0.6352534630490332\n",
      " F1 Score: 0.644785486621467\n",
      " Precision: 0.6284537260213509\n",
      " Recall: 0.6619887284601822\n",
      " AUC: 0.6352494524898191\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest 01\")\n",
    "print(\" RMSE: %s\" % rmse)\n",
    "print(\" MAE: %s\" % mae)\n",
    "print(\" Log Loss: %s\" % logloss)\n",
    "print(\" Accuracy: %s\" % accuracy)\n",
    "print(\" F1 Score: %s\" % F1)\n",
    "print(\" Precision: %s\" % precision)\n",
    "print(\" Recall: %s\" % recall)\n",
    "print(\" AUC: %s\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo 2**\n",
    "\n",
    "~~~python\n",
    "RandomForestClassifier(criterion = 'gini', max_depth = 6, n_jobs = -1, oob_score = True,\n",
    "                       n_estimators = 200, max_features = \"auto\", min_samples_leaf = 200)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos 'mlflow'\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Cargamos el modelo 02\n",
    "    pkl_filename_02 = \"modelos/random_forest_02.pkl\"\n",
    "    with open(pkl_filename_02, 'rb') as file:\n",
    "        rf_model_02 = pickle.load(file)\n",
    "        \n",
    "    # Obtenemos las predicciones con el modelo 01  \n",
    "    predict_02 = rf_model_02.predict(X_val)\n",
    "    \n",
    "    # Calculamos diversas medidas\n",
    "    (rmse, mae, logloss, accuracy, F1, precision, recall, auc) = eval_metricas(y_val, predict_02)\n",
    "\n",
    "    # Log mlflow parámetros\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"logloss\", logloss)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"F1\", F1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    # Log modelo generado\n",
    "    mlflow.sklearn.log_model(rf_model_02, \"RFmodel02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 02\n",
      " RMSE: 0.6131294135194802\n",
      " MAE: 0.3759276777227418\n",
      " Log Loss: 12.984252090973918\n",
      " Accuracy: 0.6240723222772582\n",
      " F1 Score: 0.6418576773820872\n",
      " Precision: 0.6129464141289714\n",
      " Recall: 0.6736313065103992\n",
      " AUC: 0.624064887930234\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest 02\")\n",
    "print(\" RMSE: %s\" % rmse)\n",
    "print(\" MAE: %s\" % mae)\n",
    "print(\" Log Loss: %s\" % logloss)\n",
    "print(\" Accuracy: %s\" % accuracy)\n",
    "print(\" F1 Score: %s\" % F1)\n",
    "print(\" Precision: %s\" % precision)\n",
    "print(\" Recall: %s\" % recall)\n",
    "print(\" AUC: %s\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística con MLflow\n",
    "\n",
    "~~~python\n",
    "# Modelo 1\n",
    "LogisticRegression()\n",
    "\n",
    "# Modelo 2\n",
    "LogisticRegression(n_jobs=-1, max_iter=300)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos 'mlflow'\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    ### Modelo 01 ###\n",
    "    \n",
    "    # Cargamos el modelo 01\n",
    "    pkl_filename_01 = \"modelos/regresion_logistica_01.pkl\"\n",
    "    with open(pkl_filename_01, 'rb') as file:\n",
    "        rl_model_01 = pickle.load(file)\n",
    "        \n",
    "    # Obtenemos las predicciones con el modelo 01  \n",
    "    predict_01 = rl_model_01.predict(X_val)\n",
    "    \n",
    "    # Calculamos diversas medidas para modelo 01\n",
    "    (rmse, mae, logloss, accuracy, F1, precision, recall, auc) = eval_metricas(y_val, predict_01)\n",
    "    \n",
    "    # Log mlflow parámetros\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"logloss\", logloss)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"F1\", F1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    # Log modelo generado\n",
    "    mlflow.sklearn.log_model(rl_model_01, \"RLmodel01\")\n",
    "    \n",
    "    # --------------------------------------------------- #\n",
    "        \n",
    "    ### Modelo 02 ###\n",
    "    \n",
    "    # Cargamos el modelo 02\n",
    "    pkl_filename_02 = \"modelos/regresion_logistica_02.pkl\"\n",
    "    with open(pkl_filename_02, 'rb') as file:\n",
    "        rl_model_02 = pickle.load(file)\n",
    "        \n",
    "    # Obtenemos las predicciones con el modelo 02  \n",
    "    predict_02 = rl_model_02.predict(X_val)\n",
    "    \n",
    "    # Calculamos diversas medidas para modelo 02\n",
    "    (rmse, mae, logloss, accuracy, F1, precision, recall, auc) = eval_metricas(y_val, predict_02)\n",
    "\n",
    "    # Log mlflow parámetros\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"logloss\", logloss)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"F1\", F1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    # Log modelo generado\n",
    "    mlflow.sklearn.log_model(rl_model_02, \"RLmodel02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo 1**\n",
    "\n",
    "~~~python\n",
    "LogisticRegression()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos 'mlflow'\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    ### Modelo 01 ###\n",
    "    \n",
    "    # Cargamos el modelo 01\n",
    "    pkl_filename_01 = \"modelos/regresion_logistica_01.pkl\"\n",
    "    with open(pkl_filename_01, 'rb') as file:\n",
    "        rl_model_01 = pickle.load(file)\n",
    "        \n",
    "    # Obtenemos las predicciones con el modelo 01  \n",
    "    predict_01 = rl_model_01.predict(X_val)\n",
    "    \n",
    "    # Calculamos diversas medidas para modelo 01\n",
    "    (rmse, mae, logloss, accuracy, F1, precision, recall, auc) = eval_metricas(y_val, predict_01)\n",
    "    \n",
    "    # Log mlflow parámetros\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"logloss\", logloss)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"F1\", F1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    # Log modelo generado\n",
    "    mlflow.sklearn.log_model(rl_model_01, \"RLmodel01\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística 01\n",
      " RMSE: 0.6313192130219785\n",
      " MAE: 0.39856394873069023\n",
      " Log Loss: 13.766043833266938\n",
      " Accuracy: 0.6014360512693098\n",
      " F1 Score: 0.573077997394292\n",
      " Precision: 0.617082943347811\n",
      " Recall: 0.5349313807180456\n",
      " AUC: 0.6014460276400377\n"
     ]
    }
   ],
   "source": [
    "print(\"Regresión Logística 01\")\n",
    "print(\" RMSE: %s\" % rmse)\n",
    "print(\" MAE: %s\" % mae)\n",
    "print(\" Log Loss: %s\" % logloss)\n",
    "print(\" Accuracy: %s\" % accuracy)\n",
    "print(\" F1 Score: %s\" % F1)\n",
    "print(\" Precision: %s\" % precision)\n",
    "print(\" Recall: %s\" % recall)\n",
    "print(\" AUC: %s\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo 2**\n",
    "\n",
    "~~~python\n",
    "LogisticRegression(n_jobs=-1, max_iter=300)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos 'mlflow'\n",
    "with mlflow.start_run():\n",
    "        \n",
    "    ### Modelo 02 ###\n",
    "    \n",
    "    # Cargamos el modelo 02\n",
    "    pkl_filename_02 = \"modelos/regresion_logistica_02.pkl\"\n",
    "    with open(pkl_filename_02, 'rb') as file:\n",
    "        rl_model_02 = pickle.load(file)\n",
    "        \n",
    "    # Obtenemos las predicciones con el modelo 02  \n",
    "    predict_02 = rl_model_02.predict(X_val)\n",
    "    \n",
    "    # Calculamos diversas medidas para modelo 02\n",
    "    (rmse, mae, logloss, accuracy, F1, precision, recall, auc) = eval_metricas(y_val, predict_02)\n",
    "\n",
    "    # Log mlflow parámetros\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"logloss\", logloss)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"F1\", F1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    # Log modelo generado\n",
    "    mlflow.sklearn.log_model(rl_model_02, \"RLmodel02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística 02\n",
      " RMSE: 0.6281548889735611\n",
      " MAE: 0.3945785645413868\n",
      " Log Loss: 13.628411310275684\n",
      " Accuracy: 0.6054214354586133\n",
      " F1 Score: 0.5981926155914526\n",
      " Precision: 0.6094510608912811\n",
      " Recall: 0.5873425822437693\n",
      " AUC: 0.6054241474687699\n"
     ]
    }
   ],
   "source": [
    "print(\"Regresión Logística 02\")\n",
    "print(\" RMSE: %s\" % rmse)\n",
    "print(\" MAE: %s\" % mae)\n",
    "print(\" Log Loss: %s\" % logloss)\n",
    "print(\" Accuracy: %s\" % accuracy)\n",
    "print(\" F1 Score: %s\" % F1)\n",
    "print(\" Precision: %s\" % precision)\n",
    "print(\" Recall: %s\" % recall)\n",
    "print(\" AUC: %s\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting con MLflow\n",
    "\n",
    "~~~python\n",
    "GradientBoostingClassifier(n_estimators=50, learning_rate=0.75, \n",
    "                           max_depth=4, validation_fraction=0.2, random_state=9)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos 'mlflow'\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Cargamos el modelo (solo hay uno)\n",
    "    pkl_filename = \"modelos/gradient_boosting.pkl\"\n",
    "    with open(pkl_filename, 'rb') as file:\n",
    "        gb_model = pickle.load(file)\n",
    "        \n",
    "    # Obtenemos las predicciones con el modelo 01  \n",
    "    predict = gb_model.predict(X_val)\n",
    "    \n",
    "    # Calculamos diversas medidas\n",
    "    (rmse, mae, logloss, accuracy, F1, precision, recall, auc) = eval_metricas(y_val, predict)\n",
    "\n",
    "    # Log mlflow parámetros\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"logloss\", logloss)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"F1\", F1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    # Log modelo generado\n",
    "    mlflow.sklearn.log_model(gb_model, \"GBmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      " RMSE: 0.5936602658835763\n",
      " MAE: 0.3524325112889586\n",
      " Log Loss: 12.172721138968884\n",
      " Accuracy: 0.6475674887110414\n",
      " F1 Score: 0.6409167592554746\n",
      " Precision: 0.6533458463624776\n",
      " Recall: 0.6289517395038116\n",
      " AUC: 0.6475702812610071\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boosting\")\n",
    "print(\" RMSE: %s\" % rmse)\n",
    "print(\" MAE: %s\" % mae)\n",
    "print(\" Log Loss: %s\" % logloss)\n",
    "print(\" Accuracy: %s\" % accuracy)\n",
    "print(\" F1 Score: %s\" % F1)\n",
    "print(\" Precision: %s\" % precision)\n",
    "print(\" Recall: %s\" % recall)\n",
    "print(\" AUC: %s\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
